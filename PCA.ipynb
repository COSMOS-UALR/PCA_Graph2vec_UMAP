{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bcab8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c5ad16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_combine_data():\n",
    "    df1 = pd.read_csv('airforce_channels_anomalous.csv')\n",
    "    df2 = pd.read_csv('random_news_channels.csv')\n",
    "    combined_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e818fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    channel_ids = df['channel_id']\n",
    "    df = df.drop(columns=['channel_id']).fillna(0)\n",
    "    return df, channel_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dabcdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Data\n",
    "def scale_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    return scaled_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1ad8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA for Dimensionality Reduction\n",
    "def perform_pca(data, n_components=2):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return pca_data, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41e210e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_k(data):\n",
    "    silhouette_scores = []\n",
    "    print(\"Evaluating K-Means clustering silhouette scores:\")\n",
    "    for k in range(2, 6):  # Change the range as needed\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data)\n",
    "        score = silhouette_score(data, labels)\n",
    "        silhouette_scores.append(score)\n",
    "        print(f\"Number of Clusters: {k}, Silhouette Score: {score:.4f}\")\n",
    "    \n",
    "    optimal_k = 2 + np.argmax(silhouette_scores)\n",
    "    return optimal_k, silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbb7e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform K-Means Clustering\n",
    "def perform_kmeans(data, n_clusters):\n",
    "    \"\"\"\n",
    "    Perform K-Means clustering.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(data)\n",
    "    return labels, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "65f07648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Cluster Data\n",
    "def save_cluster_data(df, labels, channel_ids):\n",
    "    \"\"\"\n",
    "    Save clusters to CSV files and validate counts.\n",
    "    \"\"\"\n",
    "    df['channel_id'] = channel_ids\n",
    "    df['cluster_id'] = labels\n",
    "    output_dir = 'clusters_output'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for cluster_id in np.unique(labels):\n",
    "        cluster_df = df[df['cluster_id'] == cluster_id]\n",
    "        cluster_df.to_csv(f\"{output_dir}/cluster_{cluster_id}.csv\", index=False)\n",
    "        print(f\"Cluster {cluster_id}: {len(cluster_df)} elements saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44fc48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot K-Means Clusters\n",
    "def plot_clusters(data, labels, title=\"Clusters\"):\n",
    "    \"\"\"\n",
    "    Plot clusters in 2D space.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(x=data[:, 0], y=data[:, 1], hue=labels, palette=\"viridis\", s=100)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"PC1\", fontsize=16)\n",
    "    plt.ylabel(\"PC2\", fontsize=16)\n",
    "    plt.legend(title=\"Cluster\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "551d1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Hierarchical Clusters\n",
    "def perform_hierarchical_clustering(data, max_clusters=10):\n",
    "    linkage_matrix = linkage(data, method=\"ward\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    dendrogram(linkage_matrix)\n",
    "    plt.title(\"Hierarchical Clustering Dendrogram\", fontsize=16)\n",
    "    plt.xlabel(\"Channel Index\", fontsize=16)\n",
    "    plt.ylabel(\"Distance\", fontsize=16)\n",
    "    plt.show()\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for k in range(2, max_clusters + 1):\n",
    "        labels = AgglomerativeClustering(n_clusters=k, linkage=\"ward\").fit_predict(data)\n",
    "        score = silhouette_score(data, labels)\n",
    "        silhouette_scores.append(score)\n",
    "        #print(f\"Number of Clusters: {k}, Silhouette Score: {score:.4f}\")\n",
    "    optimal_k = 2 + np.argmax(silhouette_scores)\n",
    "    return optimal_k, silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f6f36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Validate Cophenetic Coefficient\n",
    "def calculate_cophenetic_coefficient(data):\n",
    "    linkage_matrix = linkage(data, method=\"ward\")\n",
    "    c, _ = cophenet(linkage_matrix, pdist(data))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf4255a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = load_and_combine_data()\n",
    "df, channel_ids = preprocess_data(df)\n",
    "scaled_data, scaler = scale_data(df)\n",
    "\n",
    "# Perform PCA\n",
    "pca_data, pca = perform_pca(scaled_data)\n",
    "\n",
    "# K-Means Clustering\n",
    "print(\"\\nPerforming K-Means Clustering...\")\n",
    "optimal_k, silhouette_scores = find_optimal_k(pca_data)\n",
    "print(f\"Optimal K for K-Means: {optimal_k}\\n\")\n",
    "labels, kmeans = perform_kmeans(pca_data, optimal_k)\n",
    "\n",
    "# Save and plot clusters\n",
    "save_cluster_data(df, labels, channel_ids)\n",
    "plot_clusters(pca_data, labels, title=\"K-Means Clusters\")\n",
    "\n",
    "# Hierarchical Clustering\n",
    "print(\"\\nPerforming Hierarchical Clustering...\")\n",
    "optimal_h_k, h_silhouette_scores = perform_hierarchical_clustering(pca_data)\n",
    "coph_coef = calculate_cophenetic_coefficient(pca_data)\n",
    "print(f\"Cophenetic Coefficient: {coph_coef:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
